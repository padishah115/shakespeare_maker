import os
import torch


class NGram:
    """Class for n-gram language model."""

    def __init__(self, fname: str | os.PathLike, context:int, training_window:int=10000):
        """
        Parameters
        ----------
            fname : str | os.PathLike
                Name of the file containing the text from which the model will learn.
            context : int
                Size of context window (i.e. context=2 is bigram, context=3 is trigram, etc.)
            training_window : int
                Number of lines in the file that the model will train on.

        """

        self.fname = fname
        self.context = context
        self.training_window = training_window

    def _get_chars(self, lines:list[str])->list[str]:
        """Produces list of characters from a given list of lines.
        
        Parameters
        ----------
            lines : list[str]
                List of lines in the text document as strings.

        Returns
        -------
            chars : list[str]
        """

        chars = []

        # Train on the specified number of lines in the file
        for line in lines[:self.training_window]:
            splitline = list(line.split(" ")) # introduce special '£' character for linebreak
            words = ['+' + word for word in splitline if word != ''] + ["£"] # introduce '+' character for space
            for word in words:
                chars += ([char for char in word])

        return chars


    def _set_mapping(self, ):
        """Generates a vocabulary for the class composed of all characters in the text, and generates both string-to-index and index-to-string
        mapping dictionaries, where the index is unique for each character in the vocabulary."""
        
        lines = open(self.fname).read().splitlines()

        # Get character list
        self.chars = self._get_chars(lines=lines)

        # Generate mapping dictionaries
        self.vocabulary = sorted(set(self.chars))
        self.stoi = {s:i for i, s in enumerate(self.vocabulary)}
        self.itos = {i:s for s, i in self.stoi.items()}

        

    def _set_probmatrix(self, smoothing:float=1e-4):
        """Sets the matrix of probabilities, i.e. how likely one character is to follow another.
        
        Parameters
        ----------
            smoothing : float
                Value to be added to all cells in the matrix so that no probability is encoded at 0.
        """

        dimensions = [len(self.vocabulary) for _ in range(self.context)]
        self.N = torch.zeros((dimensions))
        char_slices = [self.chars[i:] for i in range(self.context)] # for creating a zip file

        zipped_chars = zip(*char_slices) # each tuple (row) is an n-gram 
        for chars in zipped_chars:
            ixs = [self.stoi[char] for char in chars]
            self.N[tuple(ixs)] += 1

        # Smoothing
        self.N += smoothing * torch.ones_like(self.N)

    def _get_generated_lines(self, lines_to_gen:int, seed:int=42)->list[str]:
        """Returns a list of lines generated by the model.
        
        Parameters
        ----------
            lines_to_gen : int
                Number of lines that the model will generate.
            seed : int
                Seed for the generator used to sample from probability distributions.

        Returns
        -------
            generated_lines : list[str]
                All lines generated by the model as strings.
        """

        generated_lines = []

        # Turn each row into a probability distribution, from which we will sample.
        prob = self.N / self.N.sum(-1, keepdim=True)

        generator = torch.Generator().manual_seed(seed)
        
        i = 0
        context = [self.stoi['£']]*(self.context-1) # Begin at start character '£'
        for i in range(lines_to_gen):
            new_line = False
            line = []
            while not new_line:

                prob_row = prob[tuple(context)]
                ix = torch.multinomial(prob_row, generator=generator, num_samples=1)
                context = context[1:] + [ix.item()]

                # if the next character is a space, append a space
                if ix.item() == self.stoi["+"]:
                    next_char = ' '
                    line.append(next_char)
                
                # if the next character is the break character, add a new line
                elif ix.item() == self.stoi["£"]:
                    i = i + 1
                    generated_lines.append(line)
                    new_line = True

                # Else, just eppane dht character
                else:
                    next_char = self.itos[ix.item()]
                    line.append(next_char)

        return generated_lines

    
    def generate_text(self, lines_to_gen:int):
        """
        Parameters
        ----------
            lines_to_gen : int
                Number of lines of text which we want the model to generate
        
        """

        # generate string-to-integer and integer-to-string mappings
        self._set_mapping()

        # Generate probability matrix encoding chance of one character following another
        self._set_probmatrix()

        # Get list of bogus lines generated by model
        generated_lines = self._get_generated_lines(lines_to_gen=lines_to_gen, seed=42)
        for line in generated_lines:
            full_line = ''.join(letter for letter in line)
            print(full_line)
